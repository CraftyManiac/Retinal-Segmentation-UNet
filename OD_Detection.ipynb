{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OD Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CraftyManiac/Retinal-Segmentation-UNet/blob/main/OD_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJln3gJqUDDo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "af3bbbf8-371e-43ef-9a8e-e620fdbdb58b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaZh27ymUFP7"
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOkwSdQ9eFiS"
      },
      "source": [
        "def point_check(pt):\n",
        "  newpt = [0,0]\n",
        "  newpt[0] = 0 if pt[0] < 0 else pt[0]\n",
        "  newpt[1] = 0 if pt[1] < 0 else pt[1]\n",
        "  return tuple(newpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veQf7ixvu_iW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "d3ce8001-daaa-4690-db7f-f41ff8511033"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.eye(4).astype(int)\n",
        "measure.label(x, connectivity=1, background=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0],\n",
              "       [0, 2, 0, 0],\n",
              "       [0, 0, 3, 0],\n",
              "       [0, 0, 0, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywo-Qa35Pwaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d8cb2c9-14ae-4c40-e411-b2f0c9b686dc"
      },
      "source": [
        "output_dim = 512\n",
        "def cropONH(imageName):\n",
        "\tdata_set = {\"n\":\"Training\", \"V\":\"Validation\", \"T\":\"Testing\"}\n",
        "\t\n",
        "\tfolderName= data_set[imageName[0]]\n",
        "\n",
        "\timg_path = \"drive/Shared drives/Capstone Summer 2020/Data/Unused/Original/\"+ folderName +\"/Images/\"+ imageName +\".jpg\"\n",
        "\n",
        "\timg_path = \"drive/Shared drives/Capstone Summer 2020/Data/new.jpg\"\n",
        "\timage = PIL.Image.open(img_path)\n",
        "\tim_w, im_h = image.size\n",
        "\tvar = round(0.15 * im_w)\n",
        "\tstarting_threshold = 240\n",
        "\twhile True:\n",
        "\t\t# load the image, convert it to grayscale, and blur it\n",
        "\t\timage = cv2.imread(img_path)\n",
        "\n",
        "\t\t# image=cv2.resize(image,(800,615))\n",
        "\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\t\t# cv2_imshow(gray)\n",
        "\t\tblur = cv2.bilateralFilter(gray,9,75,75)\n",
        "\t\tmedian=cv2.medianBlur(gray,5)\n",
        "\n",
        "\t\t# cv2_imshow(median)\n",
        "\n",
        "\t\t# threshold the image to reveal light regions in the\n",
        "\t\t# blurred image\n",
        "\t\tthresh = cv2.threshold(median, starting_threshold, 255, cv2.THRESH_BINARY)[1]\n",
        "\t\tcv2_imshow(thresh)\n",
        "\n",
        "\t\t# perform a series of erosions and dilations to remove\n",
        "\t\t# any small blobs of noise from the thresholded image\n",
        "\t\tthresh = cv2.erode(thresh, None, iterations=2)\n",
        "\t\tthresh = cv2.dilate(thresh, None, iterations=4)\n",
        "\t\tcv2_imshow(thresh)\n",
        "\t\t# perform a connected component analysis on the thresholded\n",
        "\t\t# image, then initialize a mask to store only the \"large\"\n",
        "\t\t# components\n",
        "\t\tlabels = measure.label(thresh, connectivity=2, background=0)\n",
        "\t\tmask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\t\treturn\n",
        "\t\tprint(labels)\n",
        "  \t\t\n",
        "\t\tprint(np.unique(labels))\n",
        "\t\tprint(\"LAB LEN++++++++++++++> \", len(np.unique(labels)))\n",
        "\t\t# cv2_imshow(cv2.Canny(thresh, 100, 200))\n",
        "\t\t# return\n",
        "\t\tlargest_blob = 0\n",
        "\t\t# loop over the unique components\n",
        "\t\tfor label in np.unique(labels):\n",
        "\t\t\t# if this is the background label, ignore it\n",
        "\t\t\tif label == 0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tprint(\"Creating mask\")\n",
        "\t\t\t# otherwise, construct the label mask and count the\n",
        "\t\t\t# number of pixels \n",
        "\t\t\tlabelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\t\t\tlabelMask[labels == label] = 255\n",
        "\t\t\tnumPixels = cv2.countNonZero(labelMask)\n",
        "\t\t\t# cv2_imshow(labelMask)\n",
        "\t\t\t# print('==============')\n",
        "\t\t\t# if the number of pixels in the component is sufficiently\n",
        "\t\t\t# large, then add it to our mask of \"large blobs\"\n",
        "\t\t\tif numPixels > largest_blob:\n",
        "\t\t\t\tlargest_blob = numPixels \n",
        "\t\t\t\tmask = labelMask\n",
        "\t\t\t# if numPixels > 100:\n",
        "\t\t\t# \tprint(\"HEEE\")\n",
        "\t\t\t# \tmask = cv2.add(mask, labelMask)\n",
        "\n",
        "\t\t# cv2_imshow(mask)\n",
        "\t\t# return\n",
        "\t\t# find the contours in the mask, then sort them from left to\n",
        "\t\t# right\n",
        "\t\tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
        "\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\t# cv2.drawContours(image, cnts, -1, (0,255,0), 3)\n",
        "\t\t# return\n",
        "\t\tprint(\"CNT LEN++++++++++++++> \", len(cnts))\n",
        "\t\tcnts = imutils.grab_contours(cnts)\n",
        "\t\n",
        "\t\t#If there is nothing found for the image\n",
        "\t\tif cnts == []:\n",
        "\t\t\tstarting_threshold -= 10\n",
        "\t\t\tprint(\"Decreasing threshold by 10. Now:\", starting_threshold)\n",
        "\t\t\tcontinue\n",
        "\t\t# print(cnts)\n",
        "\n",
        "\t\tcv2_imshow(mask)\n",
        "\t\tcnts = contours.sort_contours(cnts)[0]\n",
        "\t\t# loop over the contours\n",
        "\t\tfor (i, c) in enumerate(cnts):\n",
        "\t\t\t# ellipse = cv2.fitEllipse(c)\n",
        "\t\t\t(x, y, w, h) = cv2.boundingRect(c)\n",
        "\n",
        "\t\t\tcenter = (round(x+(w/2)), round(y+(h/2)))\n",
        "\t\t\t\n",
        "\t\t\tcv2.putText(image, \"O\", center,\n",
        "\t\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "   \n",
        "\t\t\tbox_radius = output_dim//2\n",
        "\n",
        "\t\t\ttl_pt = [center[0]-box_radius, center[1]-box_radius]\n",
        "\t\t\tbr_pt = [center[0]+box_radius, center[1]+box_radius]\n",
        "\n",
        "\t\t\t#Check if TL point is out of bounds\n",
        "\t\t\tif tl_pt[0] < 0:\n",
        "\t\t\t\tneg = tl_pt[0] * -1\n",
        "\t\t\t\ttl_pt[0] = 0\n",
        "\t\t\t\tbr_pt[0] += neg\n",
        "\n",
        "\t\t\tif tl_pt[1] < 0:\n",
        "\t\t\t\tneg = tl_pt[1] * -1\n",
        "\t\t\t\ttl_pt[1] = 0\n",
        "\t\t\t\tbr_pt[1] += neg\n",
        "\n",
        "\t\t\t#Check if BR point is out of bounds\n",
        "\t\t\tif br_pt[0] > im_w:\n",
        "\t\t\t\tpos = im_w-br_pt[0]\n",
        "\t\t\t\tbr_pt[0] = im_w\n",
        "\t\t\t\ttl_pt[0] -= pos\n",
        "\t\t\tif br_pt[1] > im_h:\n",
        "\t\t\t\tpos = im_h-br_pt[1]\n",
        "\t\t\t\tbr_pt[1] = im_h\n",
        "\t\t\t\ttl_pt[1] -= pos\n",
        "\n",
        "\t\t\t# tl_pt = point_check((x-var,y-var))\n",
        "\t\t\t# br_pt = point_check((x+w+var,y+h+var))\n",
        "\t\t\tcv2.rectangle(image,tuple(tl_pt) , tuple(br_pt), (255,0,0), 3)\n",
        "\t\t\t\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\tprint(\"Wid: \", br_pt[0]-tl_pt[0], \"\\tHei:\", br_pt[1]-tl_pt[1])\t\t\t\n",
        "\t\t# image=cv2.resize(image,(512,512))\n",
        "\t\tcv2_imshow(image)\n",
        "\t\tbreak\n",
        "\treturn tl_pt[0], tl_pt[1], br_pt[0], br_pt[1]\n",
        "cropONH(\"V0001\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1634x1634 at 0x7FF926C64048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1634x1634 at 0x7FF926C64048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVsfJdy2SqDu"
      },
      "source": [
        "# for i in range(356, 401):\n",
        "#     img_name = \"T\" + str(i).zfill(4)\n",
        "#     print(img_name)\n",
        "#     cropONH(img_name)\n",
        "\n",
        "cropONH(\"V0001\")\n",
        "#n231 361 309\n",
        "#T0118 crash + more in phone\n",
        "\n",
        "\n",
        "\n",
        "#n0309 and T0397, n0322\n",
        "\n",
        "#T0128 and n0348 are fixed with greater box size\n",
        "\n",
        "#V351 is ok; 213 and 193 are bad"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}